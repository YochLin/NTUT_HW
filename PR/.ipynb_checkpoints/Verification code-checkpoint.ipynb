{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "# from lxml import html\n",
    "import matplotlib.pyplot as plt\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import imutils\n",
    "from PIL import Image\n",
    "import io \n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jtplot submodule from jupyterthemes\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "# currently installed theme will be used to\n",
    "# set plot style if no arguments provided\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抓取驗證碼圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.PhantomJS()   ## 使用 PhantomJS 能將 JS動態處理的結果顯示出來\n",
    "driver.get('https://nportal.ntut.edu.tw/index.do?thetime=1544083343415')   ##獲取網站原始碼\n",
    "element = driver.find_element_by_id('authImage')   ## 找尋驗證碼 ID\n",
    "for i in range(1):\n",
    "    element.click()    ## 對驗證碼做點擊動作\n",
    "    img = BeautifulSoup(driver.page_source, 'xml').find(id='authImage')   ## 找尋驗證碼 html\n",
    "    img_URL = \"https://nportal.ntut.edu.tw/\" + img['src']    ## 取得驗證碼來源\n",
    "    request = requests.get(img_URL)                          ## 獲得驗證碼來源 URL\n",
    "    with open('./image/image_{}.png'.format(i), 'wb') as f: \n",
    "        f.write(request.content)                             ## 存取圖片\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  確認單一字母是否有被分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ieie.png\n",
    "# ab = [[78, 18, 11, 12], [57, 18, 3, 12], [34, 18, 11, 12], [13, 18, 3, 12], [57, 14, 3, 2], [13, 14, 3, 2]]\n",
    "\n",
    "## 找出x邊界相同或是在裡面的邊框(確定是否相同單字卻被分割)\n",
    "## (i j 上面點點就是會被分割掉)\n",
    "def GetContoursDiff(arr):\n",
    "    list_ = []\n",
    "    for i in range(len(arr)):\n",
    "        x1 = arr[i][0]       ##  x座標\n",
    "        w1 = arr[i][2]       ##  寬度\n",
    "        bounding = x1 + w1   \n",
    "        \n",
    "        main_img = 0\n",
    "        sub_img = 0\n",
    "        for j in range(len(arr)):\n",
    "            if(i != j):\n",
    "                if(arr[j][0] > x1 and arr[j][0] < bounding):   # 在 x ~ x+w 內的 做紀錄\n",
    "                    main_img = i\n",
    "                    sub_img = j\n",
    "                    list_.append((main_img, sub_img))\n",
    "                elif(arr[j][0] == x1 and arr[j][2] == w1):    # 與 x, w 相等 做紀錄\n",
    "                    main_img = i\n",
    "                    sub_img = j\n",
    "                    if(main_img < sub_img):\n",
    "                        list_.append((main_img, sub_img))                    \n",
    "\n",
    "    return list_\n",
    "## 相同單字的邊界做合併     \n",
    "def  MergeContour(srcArr, changeArr):\n",
    "    list_ = []\n",
    "    arrCopy = srcArr.copy()     ## 複製一份，以免後續處理被覆蓋掉\n",
    "    for main, sub in changeArr:\n",
    "        diff = srcArr[main][1] - srcArr[sub][1]\n",
    "        arrCopy[main][1] = srcArr[sub][1]\n",
    "        arrCopy[main][3] = srcArr[main][3] + diff\n",
    "        arrCopy.remove(srcArr[sub])          ## 因為有複製一份所以移除內容並不會對原始做改變\n",
    "    return arrCopy\n",
    "\n",
    "# MergeContour(ab, GetContoursDiff(ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將圖片做切割並儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}                       ## 字母存取與計算數量\n",
    "OUTPUT_FOLDER = 'Extract_image'   ## 輸出資料夾\n",
    "\n",
    "\n",
    "for image_path in glob.glob('./image/*.png'):\n",
    "    image_name = image_path.split('\\\\')[1]\n",
    "    image_name = image_name.split('.')[0]\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 在外圍多加8格\n",
    "    gray = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    #     blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    ret, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)\n",
    "    i, contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # cv2.drawContours(img, contours, -1, (0,0,0), thickness= 1)    ## 畫出邊緣偵測\n",
    "\n",
    "    letter_regions = []\n",
    "\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "    #     cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 1)    ## 畫出框出來的矩形\n",
    "        letter_regions.append([x, y, w, h])\n",
    "\n",
    "    new_letter = MergeContour(letter_regions, GetContoursDiff(letter_regions))    \n",
    "    if len(new_letter) != 4:\n",
    "        continue\n",
    "    ## 以 x 座標做排序， 確保處理的時候是從左邊開始                    \n",
    "    new_letter = sorted(new_letter, key=lambda x: x[0])\n",
    "\n",
    "    for letter_bounding_box, letter_text in zip(new_letter, image_name):\n",
    "        \n",
    "        x, y, w, h = letter_bounding_box\n",
    "\n",
    "        # Extract the letter from the original image with a 2-pixel margin around the edge\n",
    "        letter_image = gray[y - 4: y + h + 4 ,  x - 4 :x + w + 4]\n",
    "\n",
    "        # Get the folder to save the image in\n",
    "        save_path = os.path.join(OUTPUT_FOLDER, letter_text)\n",
    "\n",
    "        # 確認資料夾是否存在，並創建\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        # write the letter image to a file\n",
    "        count = counts.get(letter_text, 1)\n",
    "        p = os.path.join(save_path, \"{}.png\".format(str(count).zfill(6)))\n",
    "        cv2.imwrite(p, letter_image)\n",
    "\n",
    "        # increment the count for the current key\n",
    "        counts[letter_text] = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181f1f53ba8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('./image/ieie.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 在外圍多加8格\n",
    "# gray = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_CONSTANT)\n",
    "\n",
    "# blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "ret, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)\n",
    "i, contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img, contours, -1, (0,0,0), thickness= 1)    ## 畫出邊緣偵測\n",
    "\n",
    "# for contour in contours:\n",
    "#     (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "#     cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 1)    ## 畫出框出來的矩形\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70, 10, 11, 12], [49, 6, 3, 16], [26, 10, 11, 12], [5, 6, 3, 16]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181f1eaa208>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "letter_regions = []\n",
    "\n",
    "for contour in contours:\n",
    "    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "#     cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 1)    ## 畫出框出來的矩形\n",
    "    letter_regions.append([x, y, w, h])\n",
    "\n",
    "new_letter = MergeContour(letter_regions, GetContoursDiff(letter_regions))\n",
    "print(new_letter)\n",
    "\n",
    "for i in new_letter:\n",
    "    x,y,w,h = i\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 1)    ## 畫出框出來的矩形\n",
    "plt.imshow(img, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('./image/ieie.png')\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# # Add some extra padding around the image\n",
    "# gray = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_CONSTANT)\n",
    "# # blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "# ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "# # i, contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# # cv2.drawContours(gray, contours, -1, (0,0,0), thickness= 1)\n",
    "# # [[75, 18, 7, 16], [31, 18, 7, 16], [79, 14, 3, 2], [35, 14, 3, 2], [57, 13, 3, 17], [13, 13, 10, 17]]\n",
    "# contours = [[78, 18, 11, 12], [57, 14, 3, 16], [34, 18, 11, 12], [13, 14, 3, 16]]\n",
    "\n",
    "# for contour in contours:\n",
    "# #     (x, y, w, h) = cv2.boundingRect(contour)\n",
    "#     (x, y, w, h) = contour\n",
    "#     print(x)\n",
    "#     cv2.rectangle(gray, (x, y), (x+w, y+h), (0,255,0), 1)\n",
    "#     print(w*h)\n",
    "# plt.imshow(gray, 'gray')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(label, classNumber):\n",
    "    onehot = []\n",
    "    for i in label:\n",
    "        letter = [0 for _ in range(classNumber)]\n",
    "        letter[i] = 1\n",
    "        onehot.append(letter)\n",
    "    return np.array(onehot)\n",
    "\n",
    "def dataProcessing(folderPath):    \n",
    "    labels = []\n",
    "    datas = []\n",
    "    i = 0\n",
    "    for labelPath in os.listdir(folderPath):\n",
    "        imgPath = glob.glob(os.path.join(folderPath, labelPath)+ \"/*.png\")\n",
    "        for path in imgPath:\n",
    "            img = cv2.imread(path, 0)\n",
    "            img = cv2.resize(img, (20,20), interpolation=cv2.INTER_CUBIC)\n",
    "#             img = img.reshape(28,28,1)\n",
    "    #         img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            labels.append(i)\n",
    "            datas.append(img)\n",
    "        i = i+1\n",
    "\n",
    "    labels = one_hot_encoder(np.array(labels), 26)\n",
    "    \n",
    "    datas = np.array(datas)\n",
    "    return datas, labels\n",
    "\n",
    "datas, labels = dataProcessing('./Extract_image/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gan Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 20\n",
    "        self.img_cols = 20\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 5 * 5, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((5, 5, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "#         (X_train, _), (_, _) = mnist.load_data()\n",
    "#         print(X_train.shape)\n",
    "#         print(X_train)\n",
    "        # Rescale -1 to 1\n",
    "        X_train = datas\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.generator.save(\"./mnist/Generate/{}.h5\".format(epoch))\n",
    "                self.discriminator.save(\"./mnist/Discriminator/{}.h5\".format(epoch))\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "#         cnt = 0\n",
    "#         for i in range(r):\n",
    "#             for j in range(c):\n",
    "#                 plt.imshow(gen_imgs[cnt, :,:,0], cmap='Greys')\n",
    "#                 plt.savefig(\"./mnist/images/image{}.png\".format(epoch))\n",
    "#                 cnt += 1\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"./mnist/images/mnist_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    dcgan.train(epochs=50000, batch_size=32, save_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 取得DCGAN訓練好的權重\n",
    "mm = load_model('./mnist/Generate/49950.h5')\n",
    "gg = load_model('./mnist/Discriminator/49950.h5')\n",
    "\n",
    "## 將GAN產生的圖片存入資料夾內\n",
    "for i in range(1000):\n",
    "    noise = np.random.normal(0, 1, (1, 100))\n",
    "    ab = mm.predict(noise)\n",
    "    ab = 127.5 * (ab + 0.5)    ###  把原本標準化變回原圖 0~255\n",
    "    bb = model.predict(ab)     ## 使用原資料訓練好的model去做預測GAN產生出來的圖形\n",
    "    cc = np.argmax(bb)\n",
    "    name = labelPre[cc]        ## 預測出來的類別\n",
    "    pictureNumber = len(os.listdir(\"./Extract_image/%s/\" %name))\n",
    "    print(name)\n",
    "    cv2.imwrite(\"./Extract_image/%s/%d.png\" %(name, pictureNumber+1), ab[0,:,:,0])\n",
    "    plt.imshow(ab[0, :,:,0], 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練驗證碼model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CNN_discriminator(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(20, 20, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(16, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "datas, labels = dataProcessing('./Extract_image/')   ### 重新取得 data & label\n",
    "model = CNN_discriminator(num_classes = 26)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "dd = np.expand_dims(datas, axis=3)   ## (846,28,28) => (846,28,28,1)\n",
    "history = model.fit(dd, labels,  epochs=1000, batch_size=32, shuffle=True)\n",
    "model.save('testModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 劃出曲線圖觀測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_fit(image, width, height):\n",
    "    \"\"\"\n",
    "    A helper function to resize an image to fit within a given size\n",
    "    :param image: image to resize\n",
    "    :param width: desired width in pixels\n",
    "    :param height: desired height in pixels\n",
    "    :return: the resized image\n",
    "    \"\"\"\n",
    "\n",
    "    # grab the dimensions of the image, then initialize\n",
    "    # the padding values\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if the width is greater than the height then resize along\n",
    "    # the width\n",
    "    if w > h:\n",
    "        image = imutils.resize(image, width=width)\n",
    "\n",
    "    # otherwise, the height is greater than the width so resize\n",
    "    # along the height\n",
    "    else:\n",
    "        image = imutils.resize(image, height=height)\n",
    "\n",
    "    # determine the padding values for the width and height to\n",
    "    # obtain the target dimensions\n",
    "    padW = int((width - image.shape[1]) / 2.0)\n",
    "    padH = int((height - image.shape[0]) / 2.0)\n",
    "\n",
    "    # pad the image then apply one more resizing to handle any\n",
    "    # rounding issues\n",
    "    image = cv2.copyMakeBorder(image, padH, padH, padW, padW,\n",
    "        cv2.BORDER_REPLICATE)\n",
    "    image = cv2.resize(image, (width, height))\n",
    "\n",
    "    # return the pre-processed image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試 網頁抓取驗證碼辨識結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\selenium\\webdriver\\phantomjs\\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picture download over!\n",
      "e\n",
      "eq\n",
      "eqt\n",
      "eqtr\n"
     ]
    }
   ],
   "source": [
    "labelPre = {0:'a', 1:'b', 2:'c', 3:'d', 4:'e', 5:'f', 6:'g', 7:'h', 8:'i', 9:'j', 10:'k', 11:'l',\n",
    "         12:'m', 13:'n', 14:'o', 15:'p', 16:'q', 17:'r', 18:'s', 19:'t', 20:'u', 21:'v', 22:'w', 23:'x',\n",
    "         24: 'y', 25:'z'}\n",
    "inputWeb = True\n",
    "model = load_model('test.h5')\n",
    "i = 0\n",
    "verify = \"\"\n",
    "\n",
    "driver = webdriver.PhantomJS()   ## 使用 PhantomJS 能將 JS動態處理的結果顯示出來\n",
    "driver.get('https://nportal.ntut.edu.tw/index.do?thetime=1544083343415')   ##獲取網站原始碼\n",
    "element = driver.find_element_by_id('authImage')   ## 找尋驗證碼 ID\n",
    "while(inputWeb):\n",
    "    img = BeautifulSoup(driver.page_source, 'xml').find(id='authImage')   ## 找尋驗證碼 html\n",
    "    img_URL = \"https://nportal.ntut.edu.tw/\" + img['src']    ## 取得驗證碼來源\n",
    "    request = requests.get(img_URL)                          ## 獲得驗證碼來源 URL\n",
    "    with open('./verify/image_{}.png'.format(i), 'wb') as f: \n",
    "        f.write(request.content)                             ## 存取圖片\n",
    "        \n",
    "    f.close\n",
    "    \n",
    "    print(\"picture download over!\")\n",
    "    \n",
    "    img = cv2.imread('./verify/image_{}.png'.format(i))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    # 在外圍多加8格\n",
    "    gray = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    #     blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    ret, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)\n",
    "    i, contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # cv2.drawContours(img, contours, -1, (0,0,0), thickness= 1)    ## 畫出邊緣偵測\n",
    "\n",
    "    letter_regions = []\n",
    "\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "    #     cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 1)    ## 畫出框出來的矩形\n",
    "        letter_regions.append([x, y, w, h])\n",
    "\n",
    "    new_letter = MergeContour(letter_regions, GetContoursDiff(letter_regions))    \n",
    "    # if len(new_letter) != 4:\n",
    "    #     break\n",
    "    ## 以 x 座標做排序， 確保處理的時候是從左邊開始                    \n",
    "    new_letter = sorted(new_letter, key=lambda x: x[0])\n",
    "    if len(new_letter) != 4:\n",
    "        continue\n",
    "    \n",
    "    for letter_bounding_box in new_letter:\n",
    "\n",
    "        x, y, w, h = letter_bounding_box\n",
    "\n",
    "        # Extract the letter from the original image with a 2-pixel margin around the edge\n",
    "        letter_image = gray[y - 4: y + h + 4 ,  x - 4 :x + w + 4]\n",
    "        letter_image = resize_to_fit(letter_image, 20, 20)\n",
    "        letter_image = np.expand_dims(letter_image, axis=2)\n",
    "        letter_image = letter_image.reshape((1,20,20,1))\n",
    "        predition = model.predict(letter_image)\n",
    "        index = np.argmax(predition)\n",
    "        verify = verify + labelPre[index]\n",
    "        print(verify)\n",
    "    i += 1\n",
    "    inputWeb = False\n",
    "    element.click()    ## 對驗證碼做點擊動作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 網頁自動登入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這次採用擷取整張瀏覽器圖片去尋找驗證碼位置，並將他擷取下來做後續的辨識，因為北科大網站的驗證碼是用 JS 動態生成，所以每次訪問的時候圖片會改變，導致於網頁上顯示的驗證碼，與實際辨識的驗證碼圖片是不相同的，目前是採取擷取瀏覽器圖片再去尋找驗證碼位置做剪取。<br/><br/>\n",
    "\n",
    "**24吋螢幕:** <br/>\n",
    "瀏覽器size: {'width': 945, 'height': 1020} <br/>\n",
    "全圖size: (929, 889) <br/>\n",
    "截圖位置： (527,237,616,266) <br/><br/>\n",
    "**32吋螢幕:** <br/>\n",
    "瀏覽器size: {'width': 1265, 'height': 1380} <br/>\n",
    "全圖size: (1249, 1249)  <br/>\n",
    "截圖位置：(687,237,776,266) <br/> <br/>\n",
    "**Mac 13.5吋螢幕:**\n",
    "瀏覽器size: {'width': 1050, 'height': 840}  <br/>\n",
    "全圖size: (1034, 709)    <br/>\n",
    "截圖位置:(579,237,668,266)   <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\n",
      "mm\n",
      "mmv\n",
      "mmva\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Browser = webdriver.PhantomJS()\n",
    "LoginUrl= ('https://nportal.ntut.edu.tw/index.do?thetime=1521358612211')\n",
    "UserName= ('yourID')\n",
    "UserPass= ('yourPassword')\n",
    "\n",
    "labelPre = {0:'a', 1:'b', 2:'c', 3:'d', 4:'e', 5:'f', 6:'g', 7:'h', 8:'i', 9:'j', 10:'k', 11:'l',\n",
    "         12:'m', 13:'n', 14:'o', 15:'p', 16:'q', 17:'r', 18:'s', 19:'t', 20:'u', 21:'v', 22:'w', 23:'x',\n",
    "         24: 'y', 25:'z'}\n",
    "inputWeb = True                       ## 確認是否進入網站\n",
    "model = load_model('testModel.h5')    ## 導入模型\n",
    "\n",
    "\n",
    "# Browser = webdriver.PhantomJS()\n",
    "Browser = webdriver.Chrome()\n",
    "Browser.get(LoginUrl)   ##獲取網站原始碼\n",
    "while(inputWeb):\n",
    "    verify = \"\"           ## 驗證碼存取變數\n",
    "    \n",
    "    screen_shot_data = Browser.get_screenshot_as_png()            ### 擷取瀏覽器圖片 (內容為 Bytes)\n",
    "    screen_shot_data = Image.open(io.BytesIO(screen_shot_data))   ## 利用 PIL 來讀取\n",
    "    img = screen_shot_data.crop((527,237,616,266))                ## 尋找驗證碼位置後，將他剪取下來\n",
    "    img = img.convert('RGB')                                      ## 轉為RGB型式\n",
    "    img = np.array(img)                                           ## 轉為 Array\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)                  ## 就能使用 OpenCV Library 來做操作了\n",
    "\n",
    "\n",
    "    # 在外圍多加8格\n",
    "    gray = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    #     blur = cv2.GaussianBlur(gray, (3,3), 0)            ## 高斯濾波器\n",
    "    ret, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)\n",
    "    i, contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # cv2.drawContours(img, contours, -1, (0,0,0), thickness= 1)    ## 畫出邊緣偵測\n",
    "\n",
    "    letter_regions = []\n",
    "\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "    #     cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 1)    ## 畫出框出來的矩形\n",
    "        letter_regions.append([x, y, w, h])\n",
    "    \n",
    "    ## 對於 i，j 上面點點做合併動作\n",
    "    new_letter = MergeContour(letter_regions, GetContoursDiff(letter_regions))    \n",
    "\n",
    "    \n",
    "    ## 以 x 座標做排序， 確保處理的時候是從左邊開始                    \n",
    "    new_letter = sorted(new_letter, key=lambda x: x[0])\n",
    "    if len(new_letter) != 4:\n",
    "        continue\n",
    "    \n",
    "    ##  找尋每個字母位置並做預測\n",
    "    for letter_bounding_box in new_letter:\n",
    "\n",
    "        x, y, w, h = letter_bounding_box\n",
    "\n",
    "        # Extract the letter from the original image with a 2-pixel margin around the edge\n",
    "        letter_image = gray[y - 4: y + h + 4 ,  x - 4 :x + w + 4]\n",
    "        letter_image = resize_to_fit(letter_image, 20, 20)\n",
    "        letter_image = np.expand_dims(letter_image, axis=2)\n",
    "        letter_image = letter_image.reshape((1,20,20,1))     ## 將圖片 reshape 為 Model 輸入型式\n",
    "        predition = model.predict(letter_image)              ## model 預測\n",
    "        index = np.argmax(predition)\n",
    "        verify = verify + labelPre[index]\n",
    "        print(verify)\n",
    "        \n",
    "    \n",
    "    Browser.find_element_by_id('muid').send_keys(UserName)        ## 輸入帳號\n",
    "    Browser.find_element_by_id('mpassword').send_keys(UserPass)   ## 輸入密碼\n",
    "    Browser.find_element_by_id('authcode').send_keys(verify)      ## 輸入驗證碼\n",
    "    time.sleep(5)\n",
    "    Browser.find_element_by_css_selector(\"input[value='登入 Login']\").click()    ## 案下登入\n",
    "    \n",
    "    try:\n",
    "        check = Browser.find_element_by_css_selector(\"input[value='重新登入']\")\n",
    "        if(inputWeb == True):\n",
    "            check.click()    ## 點擊重新登入\n",
    "    except:\n",
    "        check = None\n",
    "        pass\n",
    "    if check != None:\n",
    "        inputWeb = True\n",
    "    else:\n",
    "        inputWeb = False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
