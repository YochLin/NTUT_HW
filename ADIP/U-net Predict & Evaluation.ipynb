{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm          ## 顯示進度條\n",
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "## 使用GPU\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jtplot submodule from jupyterthemes\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "# currently installed theme will be used to\n",
    "# set plot style if no arguments provided\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 因為 plt 轉為 RGB 要使用 CV 寫入圖片要再轉回 BGR\n",
    "def cv_write(fileName, img):\n",
    "    r,g,b = cv2.split(img)\n",
    "    img = cv2.merge([b,g,r])\n",
    "    cv2.imwrite(fileName, img)\n",
    "\n",
    "##   將原圖與預測出來的遮罩合併在一起，去掉背景\n",
    "##   imgPath : 圖片路徑\n",
    "##   model : 訓練完的模型\n",
    "def removeBackground(imgPath, model):\n",
    "    path = imgPath.split('/')[-1]\n",
    "    imgOrg = cv2.imread(imgPath)\n",
    "    width, height = imgOrg.shape[:2]\n",
    "    img = cv2.resize(imgOrg, (256, 256))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    mask = model.predict(img)\n",
    "    mask = (mask > 0.5).astype(np.uint8)                    ### 因為 sigmoid 結果為 0~1 之間，所以要取一半作為臨界值\n",
    "    mask = np.squeeze(mask)                                 #### 將 mask 降維   (256,256,1) -> (256,256)\n",
    "    mask = cv2.resize(mask, (height, width), interpolation=cv2.INTER_CUBIC)\n",
    "    b,g,r = cv2.split(imgOrg)       # get b,g,r\n",
    "    imgOrg = cv2.merge([r,g,b])     # switch it to rgb\n",
    "    remove = cv2.bitwise_and(imgOrg, imgOrg, mask= mask)\n",
    "    cv_write('./humanparsing/ModifyPredict/%s' % path, remove)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(121)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(imgOrg)\n",
    "    plt.subplot(122)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_10/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=4690714, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_10/truncated_normal/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op u'conv2d_10/truncated_normal/TruncatedNormal', defined at:\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tornado/ioloop.py\", line 1073, in start\n    handler_func(fd_obj, events)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-f4ba2ed05b7d>\", line 1, in <module>\n    model = load_model('./humanparsing/Weight/model-person_seg.h5', custom_objects={'mean_iou': mean_iou})\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/saving.py\", line 419, in load_model\n    model = _deserialize_model(f, custom_objects, compile)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/saving.py\", line 225, in _deserialize_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/saving.py\", line 458, in model_from_config\n    return deserialize(config, custom_objects=custom_objects)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/utils/generic_utils.py\", line 145, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/network.py\", line 1032, in from_config\n    process_node(layer, node_data)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/network.py\", line 991, in process_node\n    layer(unpack_singleton(input_tensors), **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/layers/convolutional.py\", line 141, in build\n    constraint=self.kernel_constraint)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/base_layer.py\", line 249, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/initializers.py\", line 214, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 4185, in truncated_normal\n    return tf.truncated_normal(shape, mean, stddev, dtype=dtype, seed=seed)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/random_ops.py\", line 174, in truncated_normal\n    shape_tensor, dtype, seed=seed1, seed2=seed2)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 850, in truncated_normal\n    name=name)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_10/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=4690714, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_10/truncated_normal/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f4ba2ed05b7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./humanparsing/Weight/model-person_seg.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'mean_iou'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmean_iou\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/saving.pyc\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/saving.pyc\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    285\u001b[0m                              ' elements.')\n\u001b[1;32m    286\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_10/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=4690714, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_10/truncated_normal/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op u'conv2d_10/truncated_normal/TruncatedNormal', defined at:\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tornado/ioloop.py\", line 1073, in start\n    handler_func(fd_obj, events)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-f4ba2ed05b7d>\", line 1, in <module>\n    model = load_model('./humanparsing/Weight/model-person_seg.h5', custom_objects={'mean_iou': mean_iou})\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/saving.py\", line 419, in load_model\n    model = _deserialize_model(f, custom_objects, compile)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/saving.py\", line 225, in _deserialize_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/saving.py\", line 458, in model_from_config\n    return deserialize(config, custom_objects=custom_objects)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/utils/generic_utils.py\", line 145, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/network.py\", line 1032, in from_config\n    process_node(layer, node_data)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/network.py\", line 991, in process_node\n    layer(unpack_singleton(input_tensors), **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/layers/convolutional.py\", line 141, in build\n    constraint=self.kernel_constraint)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/base_layer.py\", line 249, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/initializers.py\", line 214, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 4185, in truncated_normal\n    return tf.truncated_normal(shape, mean, stddev, dtype=dtype, seed=seed)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/random_ops.py\", line 174, in truncated_normal\n    shape_tensor, dtype, seed=seed1, seed2=seed2)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 850, in truncated_normal\n    name=name)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_10/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=4690714, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_10/truncated_normal/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./humanparsing/Weight/model-person_seg.h5', custom_objects={'mean_iou': mean_iou})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "removeBackground('./test_data/images/2.jpeg', model)\n",
    "end = time.time()\n",
    "print(\"Programing time: %.2f\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = cv2.imread('./test_data/gt/gt6.PNG')\n",
    "pred = cv2.imread('./humanparsing/ModifyPredict/6.jpeg')\n",
    "real = cv2.resize(real, (pred.shape[1], pred.shape[0]), \n",
    "                               interpolation=cv2.INTER_CUBIC)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(121)\n",
    "plt.grid(False)\n",
    "plt.imshow(real)\n",
    "plt.subplot(122)\n",
    "plt.grid(False)\n",
    "plt.imshow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision_Recall(realImg, predImg, height, width, channel):\n",
    "    TP = 0.0\n",
    "    FP = 0.0\n",
    "    FN = 0.0\n",
    "    TN = 0.0\n",
    "    for k in range(channel):\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if realImg[i, j, k] == True:\n",
    "                    if predImg[i, j, k] == True:\n",
    "                        TP += 1\n",
    "                    elif predImg[i, j, k] == False:\n",
    "                        FN += 1\n",
    "                elif realImg[i, j, k] == False:\n",
    "                    if predImg[i, j, k] == True:\n",
    "                        FP += 1\n",
    "                    elif predImg[i, j, k] == False:\n",
    "                        TN += 1\n",
    "    print(TP, FP, FN, TN)\n",
    "    print(\"Precision: %.4f\" % (TP / (TP + FP)))\n",
    "    print(\"Recall: %.4f\" % (TP / (TP + FN)))\n",
    "    print(\"F1: %.4f\" % ((2 * TP) / (2*TP + FP + FN)))\n",
    "    return (TP / (TP + FP)), (TP / (TP + FN)), ((2 * TP) / (2*TP + FP + FN))\n",
    "# Precision_Recall(real_, pred_, h, w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(realImg, predImg, height, width, channel):\n",
    "    mae = 0.0\n",
    "    for k in range(channel):\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                mae += abs(float(predImg[i, j, k]) - float(realImg[i, j, k]))\n",
    "    print(\"MAE : %.4f\" % (mae / (height * width)))\n",
    "    return (mae / (height * width))\n",
    "# MAE(real, pred, h, w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeBackground(imgPath, model):\n",
    "    path = imgPath.split('/')[-1]\n",
    "    path = path.split('.')[0]\n",
    "    imgOrg = cv2.imread(imgPath)\n",
    "    width, height = imgOrg.shape[:2]\n",
    "    img = cv2.resize(imgOrg, (256, 256))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    start = time.time()\n",
    "    mask = model.predict(img)\n",
    "    end = time.time()\n",
    "    mask = (mask > 0.5).astype(np.uint8)                    ### 因為 sigmoid 結果為 0~1 之間，所以要取一半作為臨界值\n",
    "    mask = np.squeeze(mask)                                 #### 將 mask 降維   (256,256,1) -> (256,256)\n",
    "    mask = cv2.resize(mask, (height, width), interpolation=cv2.INTER_CUBIC)\n",
    "    b,g,r = cv2.split(imgOrg)       # get b,g,r\n",
    "    imgOrg = cv2.merge([r,g,b])     # switch it to rgb\n",
    "    remove = cv2.bitwise_and(imgOrg, imgOrg, mask= mask)\n",
    "#     cv_write('./humanparsing/ModifyPredict/%s.png' % path, remove)\n",
    "    return (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(721602.0, 24636.0, 9468.0, 1088574.0)\n",
      "Precision: 0.9670\n",
      "Recall: 0.9870\n",
      "F1: 0.9769\n",
      "MAE : 5.3618\n",
      "===============================================\n",
      "2\n",
      "(207642.0, 2658.0, 14978.0, 1597186.0)\n",
      "Precision: 0.9874\n",
      "Recall: 0.9327\n",
      "F1: 0.9593\n",
      "MAE : 4.9316\n",
      "===============================================\n",
      "3\n",
      "(980957.0, 503.0, 24191.0, 914349.0)\n",
      "Precision: 0.9995\n",
      "Recall: 0.9759\n",
      "F1: 0.9876\n",
      "MAE : 5.2795\n",
      "===============================================\n",
      "4\n",
      "(740094.0, 526.0, 18031.0, 1083577.0)\n",
      "Precision: 0.9993\n",
      "Recall: 0.9762\n",
      "F1: 0.9876\n",
      "MAE : 5.1962\n",
      "===============================================\n",
      "5\n",
      "(883782.0, 15869.0, 35445.0, 878938.0)\n",
      "Precision: 0.9824\n",
      "Recall: 0.9614\n",
      "F1: 0.9718\n",
      "MAE : 7.2120\n",
      "===============================================\n",
      "6\n",
      "(8938795.0, 51334.0, 632485.0, 10870188.0)\n",
      "Precision: 0.9943\n",
      "Recall: 0.9339\n",
      "F1: 0.9632\n",
      "MAE : 12.5361\n",
      "===============================================\n",
      "7\n",
      "(688919.0, 7711.0, 32171.0, 968275.0)\n",
      "Precision: 0.9889\n",
      "Recall: 0.9554\n",
      "F1: 0.9719\n",
      "MAE : 4.9229\n",
      "===============================================\n",
      "8\n",
      "(922158.0, 54125.0, 29348.0, 803171.0)\n",
      "Precision: 0.9446\n",
      "Recall: 0.9692\n",
      "F1: 0.9567\n",
      "MAE : 10.2054\n",
      "===============================================\n",
      "9\n",
      "(381423.0, 375.0, 36736.0, 1390268.0)\n",
      "Precision: 0.9990\n",
      "Recall: 0.9121\n",
      "F1: 0.9536\n",
      "MAE : 7.4794\n",
      "===============================================\n",
      "10\n",
      "(9731752.0, 157880.0, 178508.0, 10424662.0)\n",
      "Precision: 0.9840\n",
      "Recall: 0.9820\n",
      "F1: 0.9830\n",
      "MAE : 4.9646\n",
      "===============================================\n",
      "11\n",
      "(356933.0, 21117.0, 40009.0, 1390743.0)\n",
      "Precision: 0.9441\n",
      "Recall: 0.8992\n",
      "F1: 0.9211\n",
      "MAE : 12.2529\n",
      "===============================================\n",
      "12\n",
      "(334041.0, 10059.0, 29987.0, 1447549.0)\n",
      "Precision: 0.9708\n",
      "Recall: 0.9176\n",
      "F1: 0.9434\n",
      "MAE : 6.3849\n",
      "===============================================\n",
      "13\n",
      "(379178.0, 3744.0, 16222.0, 1409658.0)\n",
      "Precision: 0.9902\n",
      "Recall: 0.9590\n",
      "F1: 0.9743\n",
      "MAE : 5.5029\n",
      "===============================================\n",
      "14\n",
      "(576486.0, 7201.0, 26608.0, 1198507.0)\n",
      "Precision: 0.9877\n",
      "Recall: 0.9559\n",
      "F1: 0.9715\n",
      "MAE : 8.5946\n",
      "===============================================\n",
      "15\n",
      "(362264.0, 2196.0, 8329.0, 1436013.0)\n",
      "Precision: 0.9940\n",
      "Recall: 0.9775\n",
      "F1: 0.9857\n",
      "MAE : 3.3955\n",
      "===============================================\n",
      "16\n",
      "(910142.0, 53080.0, 23515.0, 2662313.0)\n",
      "Precision: 0.9449\n",
      "Recall: 0.9748\n",
      "F1: 0.9596\n",
      "MAE : 5.4307\n",
      "===============================================\n",
      "17\n",
      "(1353175.0, 1499.0, 24618.0, 429510.0)\n",
      "Precision: 0.9989\n",
      "Recall: 0.9821\n",
      "F1: 0.9904\n",
      "MAE : 4.4961\n",
      "===============================================\n",
      "18\n",
      "(559040.0, 1181.0, 40277.0, 3044502.0)\n",
      "Precision: 0.9979\n",
      "Recall: 0.9328\n",
      "F1: 0.9642\n",
      "MAE : 3.5459\n",
      "===============================================\n",
      "19\n",
      "(147108.0, 4082.0, 13504.0, 1644108.0)\n",
      "Precision: 0.9730\n",
      "Recall: 0.9159\n",
      "F1: 0.9436\n",
      "MAE : 2.9482\n",
      "===============================================\n",
      "20\n",
      "(567014.0, 1662.0, 104001.0, 19820125.0)\n",
      "Precision: 0.9971\n",
      "Recall: 0.8450\n",
      "F1: 0.9148\n",
      "MAE : 1.8432\n",
      "===============================================\n",
      "21\n",
      "(6281468.0, 48653.0, 197005.0, 11490874.0)\n",
      "Precision: 0.9923\n",
      "Recall: 0.9696\n",
      "F1: 0.9808\n",
      "MAE : 14.4154\n",
      "===============================================\n",
      "22\n",
      "(713978.0, 837.0, 27602.0, 1066385.0)\n",
      "Precision: 0.9988\n",
      "Recall: 0.9628\n",
      "F1: 0.9805\n",
      "MAE : 4.3010\n",
      "===============================================\n",
      "23\n",
      "(525544.0, 5833.0, 10403.0, 1265120.0)\n",
      "Precision: 0.9890\n",
      "Recall: 0.9806\n",
      "F1: 0.9848\n",
      "MAE : 4.7149\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "mae = []\n",
    "time_ = []\n",
    "for i in range(23):\n",
    "    i = i + 1\n",
    "    print(i)\n",
    "    tt = removeBackground('./test_data/images/%d.jpeg' % i, model)\n",
    "    real = cv2.imread('./test_data/gt/gt%d.PNG' % i)\n",
    "    pred = cv2.imread('./humanparsing//%d.png' % i)\n",
    "    real = cv2.resize(real, (pred.shape[1], pred.shape[0]), \n",
    "                                   interpolation=cv2.INTER_CUBIC)\n",
    "    real_ = real.astype(np.bool)\n",
    "    pred_ = pred.astype(np.bool)\n",
    "    h = pred.shape[0]\n",
    "    w = pred.shape[1]\n",
    "    c = pred.shape[2]\n",
    "    p, r, f = Precision_Recall(real_, pred_, h, w, c)\n",
    "    ma = MAE(real, pred, h, w, c)\n",
    "    precision.append(p)\n",
    "    recall.append(r)\n",
    "    f1.append(f)\n",
    "    mae.append(ma)\n",
    "    time_.append(tt)\n",
    "    print(\"===============================================\")\n",
    "precision = np.array(precision).reshape(-1,1)\n",
    "recall = np.array(recall).reshape(-1,1)\n",
    "f1 = np.array(f1).reshape(-1,1)\n",
    "mae = np.array(mae).reshape(-1,1)\n",
    "time_ = np.array(time_).reshape(-1,1)\n",
    "saveExcel = np.hstack((precision, recall, f1, mae, time_))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pd.DataFrame(saveExcel)\n",
    "excel.columns = ['Precision', 'Recall', 'F1-Measure', 'MAE', 'time']\n",
    "excel.to_csv('./modelModify_Precision_Recall.csv',float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 風景與人物合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "# Read the images\n",
    "foreground = cv2.imread(\"./DataAndMask/Original/man-person-jumping-desert.png\")\n",
    "background = cv2.imread(\"./DataAndMask/g3HmWc0.jpg\")\n",
    "alpha = cv2.imread(\"./DataAndMask/label/man-person-jumping-desert.png\")\n",
    "background = cv2.resize(background, (foreground.shape[1], foreground.shape[0]), \n",
    "                                interpolation=cv2.INTER_CUBIC)\n",
    " \n",
    "# Convert uint8 to float\n",
    "foreground = foreground.astype(float)\n",
    "background = background.astype(float)\n",
    " \n",
    "# Normalize the alpha mask to keep intensity between 0 and 1\n",
    "alpha = alpha.astype(float)/255\n",
    " \n",
    "# Multiply the foreground with the alpha matte\n",
    "foreground = cv2.multiply(alpha, foreground)\n",
    " \n",
    "# Multiply the background with ( 1 - alpha )\n",
    "background = cv2.multiply(1.0 - alpha, background)\n",
    " \n",
    "# Add the masked foreground and background.\n",
    "outImage = cv2.add(foreground, background)\n",
    "\n",
    "outImage = outImage/255\n",
    "saveImg = np.zeros((foreground.shape[0], foreground.shape[1], 3))\n",
    "cv2.normalize(outImage, saveImg, 0, 255, cv2.NORM_MINMAX)\n",
    "print(outImage.shape)\n",
    "\n",
    "# Display image\n",
    "plt.imshow(outImage)\n",
    "cv2.imwrite('tt.png', saveImg)\n",
    "# cv2.imshow(\"outImg\", outImage/255)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將黑色背景變透明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(23):\n",
    "    i = i+1\n",
    "    image = cv2.imread('./humanparsing/OriginalPredict/%d.png' % i)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    image[np.all(image == [0, 0, 0, 255], axis=2)] = [0, 0, 0, 0]      #### 將 alpha 設為 0 \n",
    "    cv2.imwrite('./humanparsing/OriginalPredict/%d.png' % i, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
